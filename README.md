# Corrida DRL

## Introdu√ß√£o

Corrida DRL √© um ambiente de corrida customizado para experimentos de Aprendizado por Refor√ßo (RL), com suporte a curr√≠culo de fases, visualiza√ß√£o gr√°fica, m√©tricas pedag√≥gicas e logging avan√ßado. O projeto permite treinar agentes RL em mapas de corredor reto e curva, com checkpoints, barreiras e dashboard interativo.

## Requisitos de Ambiente

- Recomenda-se utilizar **Python 3.10** ou **Python 3.11** para m√°xima compatibilidade com as bibliotecas RL (Stable-Baselines3, Torch, Gym, etc.).
- O projeto foi testado no Windows, mas tamb√©m √© compat√≠vel com Linux e Mac.
- Evite Python 3.12 ou superior, pois pode haver incompatibilidades com algumas depend√™ncias RL.

Para instalar o Python recomendado, acesse: https://www.python.org/downloads/

## Instala√ß√£o

1. Clone o reposit√≥rio:
   ```bash
   git clone <url-do-repo>
   cd corrida_drl
   ```
2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

## Uso

Execute o treinamento e visualiza√ß√£o com:
```bash
python main.py
```

Op√ß√µes de linha de comando:
- `--skip-training`: Pula o treinamento e carrega modelo pr√©-treinado (se existir).

Durante a execu√ß√£o, escolha o mapa/fase desejado pelo prompt interativo.

## Exemplo de config.json

Voc√™ pode criar um arquivo `config.json` no diret√≥rio raiz para definir hiperpar√¢metros e configura√ß√µes do experimento. O conte√∫do pode ser, por exemplo:

```json
{
  "learning_rate": 0.0003,
  "gamma": 0.98,
  "n_parallel": 4,
  "map_type": "corridor"
}
```

Para usar, basta rodar:

```
python main.py --config config.json
```

Argumentos passados pela linha de comando sobrescrevem os valores do JSON.

## Exemplos

- Interface gr√°fica mostrando o ambiente, carros, barreiras e checkpoints.
- Dashboard em tempo real com gr√°ficos de recompensa, colis√£o e penaliza√ß√£o.

![Exemplo da interface](docs/interface_exemplo.png)
![Dashboard](docs/dashboard_exemplo.png)

## Resultados

Exemplo de gr√°fico de desempenho ap√≥s treinamento:

![Gr√°fico de recompensas](docs/grafico_recompensa.png)

- Recompensa m√©dia crescente indica aprendizado.
- Colis√µes diminuindo ao longo do tempo.

## Estrutura do Projeto

- `main.py`: Loop principal de treinamento, avalia√ß√£o e interface.
- `environment.py`: Ambiente customizado Gym, l√≥gica de f√≠sica, checkpoints e recompensas.
- `agent.py`: Classe do agente RL (DQN), treinamento, avalia√ß√£o e callbacks.
- `interface.py`: Visualiza√ß√£o gr√°fica (pygame) e dashboard (matplotlib/tkinter).
- `metrics.py`: Utilit√°rios para m√©tricas e gr√°ficos.
- `config.py`: Par√¢metros globais, fases e curr√≠culo.
- `logger.py`: Configura√ß√£o de logging avan√ßado.
- `tests/`: Testes unit√°rios com pytest.
- `requirements.txt`: Depend√™ncias do projeto.

## üéØ Status Final & Valida√ß√£o

### ‚úÖ Projeto Completo e Pronto!

Seu projeto est√° **funcional, testado e visualmente polido**. Veja:

- **[STATUS_FINAL.txt](STATUS_FINAL.txt)** - Situa√ß√£o atual resumida (5 min)
- **[ROTEIRO_FINAL_VALIDACAO.md](ROTEIRO_FINAL_VALIDACAO.md)** - Teste passo-a-passo (10 min)
- **[CORRECOES_FINAIS_APLICADAS.md](CORRECOES_FINAIS_APLICADAS.md)** - Detalhes t√©cnicos das corre√ß√µes

### üìà Plano de A√ß√£o & Melhorias Futuras

Para **pr√≥ximas melhorias**, veja o **[PLANO_ACAO.md](PLANO_ACAO.md)** com o plano estruturado em 3 fases para transform√°-lo em um **portf√≥lio standout**.

## üìñ Documenta√ß√£o Completa

Toda a documenta√ß√£o est√° bem organizada e estruturada. Veja **[ORGANIZACAO_DOCS.md](ORGANIZACAO_DOCS.md)** para uma vis√£o completa da organiza√ß√£o.

A documenta√ß√£o est√° dividida em categorias:

### üìö Documentos Principais
- **[README_PRODUCTION.md](README_PRODUCTION.md)**: Arquitetura profissional e guia de produ√ß√£o
- **[QUICKSTART.md](QUICKSTART.md)**: Come√ßar em 5 minutos
- **[BENCHMARKS.md](BENCHMARKS.md)**: Resultados de benchmarks (DQN vs PPO vs SAC)
- **[CONTRIBUTING.md](CONTRIBUTING.md)**: Guia para colaboradores

### üìñ Evolu√ß√£o do Projeto
Toda a documenta√ß√£o sobre evolu√ß√£o, corre√ß√µes, gamifica√ß√£o e detalhes t√©cnicos est√° em:
**[docs/evolution/README.md](docs/evolution/README.md)** - √çndice naveg√°vel com 20+ documentos

Conte√∫do inclui:
- Arquitetura cient√≠fica de RL
- Sistema de gamifica√ß√£o e RPG
- Todas as corre√ß√µes implementadas
- Guias de implementa√ß√£o t√©cnica
- Valida√ß√£o e testes
- Hist√≥rico de atualiza√ß√µes

### üéØ Come√ßo R√°pido por Perfil
- **Usu√°rios novos**: [QUICKSTART.md](QUICKSTART.md) ‚Üí [docs/evolution/GUIA_RAPIDO_V2.md](docs/evolution/GUIA_RAPIDO_V2.md)
- **Desenvolvedores**: [README_PRODUCTION.md](README_PRODUCTION.md) ‚Üí [docs/evolution/ARQUITETURA_RL_CIENTIFICA.md](docs/evolution/ARQUITETURA_RL_CIENTIFICA.md)
- **Pesquisadores**: [BENCHMARKS.md](BENCHMARKS.md) ‚Üí [docs/evolution/IMPLEMENTACAO_COMPLETA.md](docs/evolution/IMPLEMENTACAO_COMPLETA.md)
- **Gerentes**: [docs/evolution/SUMARIO_FINAL_v2.1.md](docs/evolution/SUMARIO_FINAL_v2.1.md)

## Como Contribuir

- Para adicionar novos mapas: edite `environment.py` e `config.py`.
- Para novos algoritmos: crie uma nova classe em `agent.py`.
- Testes: adicione fun√ß√µes em `tests/` usando pytest.
- Sugest√µes e issues s√£o bem-vindos!
- Veja [CONTRIBUTING.md](CONTRIBUTING.md) para detalhes completos.

## Testes

Execute todos os testes unit√°rios com:
```bash
pytest tests/
```

Cobertura de testes:
- Core modules: >80%
- Total de testes: 17 (todos passando)
- Plataformas: Windows, Ubuntu | Python 3.10, 3.11

## Monitoramento

O projeto inclui monitoramento integrado:

- **TensorBoard**: Visualize curvas de treinamento em tempo real
  ```bash
  tensorboard --logdir tensorboard_logs
  ```
  Acesse: http://localhost:6006

- **MLflow**: Rastreamento autom√°tico de experimentos
  ```bash
  mlflow ui
  ```
  Acesse: http://localhost:5000

## Estat√≠sticas do Projeto v2.0

- **C√≥digo**: 1.460 linhas (core/)
- **Testes**: 17 testes, >80% cobertura
- **Documenta√ß√£o**: 30+ documentos
- **Type hints**: 100%
- **CI/CD**: 5 jobs autom√°ticos (GitHub Actions)

## Licen√ßa

MIT. Sinta-se livre para usar e modificar.
